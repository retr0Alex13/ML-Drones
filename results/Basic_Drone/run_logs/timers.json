{
    "name": "root",
    "gauges": {
        "FPV-Drone.Policy.Entropy.mean": {
            "value": 2.549582004547119,
            "min": 2.495210647583008,
            "max": 3.232313632965088,
            "count": 26
        },
        "FPV-Drone.Policy.Entropy.sum": {
            "value": 76663.3828125,
            "min": 74736.546875,
            "max": 102234.8515625,
            "count": 26
        },
        "FPV-Drone.Environment.EpisodeLength.mean": {
            "value": 62.59957627118644,
            "min": 55.650283553875234,
            "max": 1388.2916666666667,
            "count": 26
        },
        "FPV-Drone.Environment.EpisodeLength.sum": {
            "value": 29547.0,
            "min": 23319.0,
            "max": 34728.0,
            "count": 26
        },
        "FPV-Drone.Step.mean": {
            "value": 779929.0,
            "min": 29842.0,
            "max": 779929.0,
            "count": 26
        },
        "FPV-Drone.Step.sum": {
            "value": 779929.0,
            "min": 29842.0,
            "max": 779929.0,
            "count": 26
        },
        "FPV-Drone.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.6555061936378479,
            "min": -0.23992551863193512,
            "max": 0.6770021319389343,
            "count": 26
        },
        "FPV-Drone.Policy.ExtrinsicValueEstimate.sum": {
            "value": 309.39892578125,
            "min": -46.305625915527344,
            "max": 358.1341247558594,
            "count": 26
        },
        "FPV-Drone.Policy.RndValueEstimate.mean": {
            "value": 0.017976021394133568,
            "min": -0.08058345317840576,
            "max": 0.1107017993927002,
            "count": 26
        },
        "FPV-Drone.Policy.RndValueEstimate.sum": {
            "value": 8.484682083129883,
            "min": -27.940277099609375,
            "max": 16.786243438720703,
            "count": 26
        },
        "FPV-Drone.Environment.CumulativeReward.mean": {
            "value": 0.809984322195336,
            "min": -1.3885599759221077,
            "max": 0.8607292977533179,
            "count": 26
        },
        "FPV-Drone.Environment.CumulativeReward.sum": {
            "value": 382.3126000761986,
            "min": -136.991399243474,
            "max": 455.3257985115051,
            "count": 26
        },
        "FPV-Drone.Policy.ExtrinsicReward.mean": {
            "value": 0.809984322195336,
            "min": -1.3885599759221077,
            "max": 0.8607292977533179,
            "count": 26
        },
        "FPV-Drone.Policy.ExtrinsicReward.sum": {
            "value": 382.3126000761986,
            "min": -136.991399243474,
            "max": 455.3257985115051,
            "count": 26
        },
        "FPV-Drone.Policy.RndReward.mean": {
            "value": 0.002745466549995245,
            "min": 0.0021346057279938604,
            "max": 0.9280102918683378,
            "count": 26
        },
        "FPV-Drone.Policy.RndReward.sum": {
            "value": 1.2958602115977556,
            "min": 1.1239808656391688,
            "max": 97.92645435594022,
            "count": 26
        },
        "FPV-Drone.Losses.PolicyLoss.mean": {
            "value": 0.06672143098737814,
            "min": 0.06426765193624497,
            "max": 0.07161425059444766,
            "count": 26
        },
        "FPV-Drone.Losses.PolicyLoss.sum": {
            "value": 0.934100033823294,
            "min": 0.8594435653299917,
            "max": 1.0306957631420413,
            "count": 26
        },
        "FPV-Drone.Losses.ValueLoss.mean": {
            "value": 0.014124380993702551,
            "min": 0.0007769516341032815,
            "max": 0.01961094746549061,
            "count": 26
        },
        "FPV-Drone.Losses.ValueLoss.sum": {
            "value": 0.1977413339118357,
            "min": 0.01087732287744594,
            "max": 0.27455326451686857,
            "count": 26
        },
        "FPV-Drone.Policy.LearningRate.mean": {
            "value": 0.00027703383979824634,
            "min": 0.00027703383979824634,
            "max": 0.00029954771553537693,
            "count": 26
        },
        "FPV-Drone.Policy.LearningRate.sum": {
            "value": 0.003878473757175449,
            "min": 0.003800585253138259,
            "max": 0.004371690612769809,
            "count": 26
        },
        "FPV-Drone.Policy.Epsilon.mean": {
            "value": 0.19234461071428574,
            "min": 0.19234461071428574,
            "max": 0.1998492384615385,
            "count": 26
        },
        "FPV-Drone.Policy.Epsilon.sum": {
            "value": 2.6928245500000005,
            "min": 2.5668617400000002,
            "max": 2.9572301899999998,
            "count": 26
        },
        "FPV-Drone.Policy.Beta.mean": {
            "value": 0.009235226610357142,
            "min": 0.009235226610357142,
            "max": 0.009984938922307693,
            "count": 26
        },
        "FPV-Drone.Policy.Beta.sum": {
            "value": 0.129293172545,
            "min": 0.126689487826,
            "max": 0.145727295981,
            "count": 26
        },
        "FPV-Drone.Losses.RNDLoss.mean": {
            "value": 0.004068367648869753,
            "min": 0.003582686185836792,
            "max": 0.30049845576286316,
            "count": 26
        },
        "FPV-Drone.Losses.RNDLoss.sum": {
            "value": 0.056957144290208817,
            "min": 0.05024100840091705,
            "max": 3.906480073928833,
            "count": 26
        },
        "FPV-Drone.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 26
        },
        "FPV-Drone.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 26
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1719578084",
        "python_version": "3.10.14 | packaged by Anaconda, Inc. | (main, Mar 21 2024, 16:20:14) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\alexu\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn config/FPV-DroneDefault.yaml --run-id=Basic_Drone",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cu117",
        "numpy_version": "1.23.1",
        "end_time_seconds": "1719579727"
    },
    "total": 1643.3870542999975,
    "count": 1,
    "self": 0.005836299995280569,
    "children": {
        "run_training.setup": {
            "total": 0.0725151000006008,
            "count": 1,
            "self": 0.0725151000006008
        },
        "TrainerController.start_learning": {
            "total": 1643.3087029000017,
            "count": 1,
            "self": 1.246909199966467,
            "children": {
                "TrainerController._reset_env": {
                    "total": 29.70208509999793,
                    "count": 1,
                    "self": 29.70208509999793
                },
                "TrainerController.advance": {
                    "total": 1612.2348406000383,
                    "count": 67116,
                    "self": 1.3364727994303394,
                    "children": {
                        "env_step": {
                            "total": 989.6327825999324,
                            "count": 67116,
                            "self": 672.1080258996117,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 316.70752930003437,
                                    "count": 67116,
                                    "self": 4.139149199658277,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 312.5683801003761,
                                            "count": 62182,
                                            "self": 312.5683801003761
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.817227400286356,
                                    "count": 67115,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1612.360225300028,
                                            "count": 67115,
                                            "is_parallel": true,
                                            "self": 1019.6318478006069,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0005658000009134412,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00016429999959655106,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0004015000013168901,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.0004015000013168901
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 592.7278116994203,
                                                    "count": 67115,
                                                    "is_parallel": true,
                                                    "self": 13.572236999822053,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 10.869859899819858,
                                                            "count": 67115,
                                                            "is_parallel": true,
                                                            "self": 10.869859899819858
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 530.9084328995923,
                                                            "count": 67115,
                                                            "is_parallel": true,
                                                            "self": 530.9084328995923
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 37.37728190018606,
                                                            "count": 67115,
                                                            "is_parallel": true,
                                                            "self": 10.231312401228934,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 27.14596949895713,
                                                                    "count": 536920,
                                                                    "is_parallel": true,
                                                                    "self": 27.14596949895713
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 621.2655852006756,
                            "count": 67115,
                            "self": 2.3331505004607607,
                            "children": {
                                "process_trajectory": {
                                    "total": 103.64061740022953,
                                    "count": 67115,
                                    "self": 103.51736140022695,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.12325600000258419,
                                            "count": 1,
                                            "self": 0.12325600000258419
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 515.2918172999853,
                                    "count": 380,
                                    "self": 221.6146731001354,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 293.67714419984986,
                                            "count": 18543,
                                            "self": 293.67714419984986
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 7.999988156370819e-07,
                    "count": 1,
                    "self": 7.999988156370819e-07
                },
                "TrainerController._save_models": {
                    "total": 0.12486720000015339,
                    "count": 1,
                    "self": 0.006996600001002662,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.11787059999915073,
                            "count": 1,
                            "self": 0.11787059999915073
                        }
                    }
                }
            }
        }
    }
}